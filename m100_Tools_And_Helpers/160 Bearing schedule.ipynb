{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #160 Bearing Schedule\n",
    "<i>Create bearing schedule as per EN1990:2023</i>\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"DataFiles/160 BearingSchedule.xlsx\" # Path to the Excel file containing load case IDS\n",
    "\n",
    "point_supports = [57, 59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reaction_components = ['FX', 'FY', 'FZ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read definitions file\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_excel(file_path, sheet_name=\"Loadcases\", usecols=range(0,3))\n",
    "\n",
    "for component in reaction_components:\n",
    "    for opt in ['max', 'min']:\n",
    "        df[component, opt] = np.nan\n",
    "\n",
    "df.columns = pd.MultiIndex.from_tuples([(i,'') if np.isscalar(i) else i for i in df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('../') # Reference modules in parent directory\n",
    "from LPI_23_0 import *\n",
    "lusas = get_lusas_modeller()\n",
    "\n",
    "if not lusas.existsDatabase():\n",
    "    raise Exception(\"This script will add loadcases to an an existing model, please open a model and run the script again.\")\n",
    "\n",
    "# Reference the current database for convenience\n",
    "db = lusas.database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_point_id_to_schedule:dict[int, pd.DataFrame] = dict()\n",
    "dict_point_id_to_node:dict[int, IFNode] = dict()\n",
    "\n",
    "for id in point_supports:\n",
    "    if not db.exists(\"Point\", id) : raise Exception(\"Point {id} is not available in the open model\")\n",
    "    dict_point_id_to_schedule[id] = df.copy()\n",
    "    \n",
    "    point:IFPoint = win32.CastTo(db.getObject(\"Point\", id), \"IFPoint\")\n",
    "    dict_point_id_to_node[id] = point.getNodes()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context:IFResultsContext = lusas.newResultsContext(lusas.view())\n",
    "obs = context.getCalcResultsSet()\n",
    "obs.remove(\"all\")\n",
    "for pid in point_supports:\n",
    "    obs.add(\"point\", pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(loadset:IFLoadset, component:str, max_min:str) -> IFResultsComponentSet:\n",
    "\n",
    "    if(loadset.getTypeCode() == 3):\n",
    "        env :IFEnvelope = win32.CastTo(loadset, \"IFEnvelope\")\n",
    "        if(max_min == \"min\" and env.isMax()):\n",
    "            loadset = env.getAssocLoadset()\n",
    "    elif(loadset.getTypeCode() == 6):\n",
    "        smart :IFSmartCombination = win32.CastTo(loadset, \"IFSmartCombination\")\n",
    "        if(max_min == \"min\" and smart.isMax()):\n",
    "            loadset = smart.getAssocLoadset()\n",
    "\n",
    "    if loadset.needsPrimaryComponent():\n",
    "        context.setActiveLoadsetAssocVal(\"Reaction\", component, loadset)\n",
    "    else:\n",
    "        context.setActiveLoadset(loadset)\n",
    "\n",
    "    return db.getResultsComponentSet(\"Reaction\", component, \"Nodal\", context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each loadcase and get the results\n",
    "for i, row in df.iterrows():\n",
    "    id = row['ID','']\n",
    "    if not isinstance(id, str) and np.isnan(id) : continue    \n",
    "    id = int(id)\n",
    "    if not db.existsLoadset(id):\n",
    "        print (f\"Loadcase {id} is not present in the model\")\n",
    "        continue\n",
    "    \n",
    "    # Get results\n",
    "    loadset = db.getLoadset(id)\n",
    "\n",
    "    for component in reaction_components:\n",
    "        for max_min in [\"max\", \"min\"]:\n",
    "            results = get_results(loadset, component, max_min)\n",
    "            iComp = results.getComponentNumber(component)\n",
    "\n",
    "            for pointID, node in dict_point_id_to_node.items():\n",
    "\n",
    "                val = results.getContinuousResults(iComp, node, None, None)\n",
    "\n",
    "                dict_point_id_to_schedule[pointID][component,max_min].iat[i] = val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(\"Bearing Schedule.xlsx\") as writer:\n",
    "    for pointID, df in dict_point_id_to_schedule.items():\n",
    "        df.to_excel(writer, sheet_name=f\"Point{pointID}\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
